{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a statistical wind model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "During the last lecture, we discussed the impotance and challenges when fitting statistical models using extreme temperatures and river runoff extremes as case studies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another area, where statistical models are important is wind development. \n",
    "\n",
    "To assess a locations wind energy potential, we need to be able to model the overall distribution of wind speeds. \n",
    "\n",
    "Getting the wind speed distribution right, matters because wind power potential ($P$) is proportional to the third power of the wind speed ($v$). \n",
    "\n",
    "$P = 1/2 \\rho A v^3$, \n",
    "\n",
    "with $\\rho$ as air density, $A$ as rotor size of a wind turbine. \n",
    "\n",
    "The map below created by the [National Renewable Energy Laboratory](https://www.nrel.gov/) shows the estimated wind energy potential in the U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.nrel.gov/gis/assets/images/wtk-140m-2017-01.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Goals\n",
    "\n",
    "- Practice fitting a statistical model the wind speed distribution\n",
    "- Modularize code as functions for easier reuse\n",
    "- Practice plotting and calculating statistics using `pandas` and `numpy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Load and clean the wind data\n",
    "\n",
    "The `data` folder contains two _*.csv_ files. One is from Phoenix uses in our last analysis (Station Code: USW00023183), the other one is taken from Charlottesville Airport. You can use either file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtasks 1.1: Load the wind data into a dataframe\n",
    "Subtasks\n",
    "\n",
    "- Load the NOAA station data into a dataframe\n",
    "- Save the the average wind speed `AWND` to a new dataframe.\n",
    "  \n",
    "  _Hint: `['<varname>']` will produce a pandas Series, while `[['<varname>>']]` will produce a pandas DataFrame_  \n",
    "- Inspect the contents of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtasks 1.2: Remove missing values \n",
    "\n",
    "You can use the `.dropna()` method to remove rows with _nan_-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed = #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Explore the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 2.1: Look at basic wind statistics\n",
    "\n",
    "_Hint: `.describe()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 2.2: Plot the wind data as a histogram\n",
    "\n",
    "Use a sufficent number of bins `bins=` so that you can see the underlying distribution. \n",
    "\n",
    "Set `density = True` to get the probability distribution rather than raw counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_speed.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taks 3: Fit a Weibull distribution to the wind data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to fit a statistical model to the data. \n",
    "\n",
    "To do so, we need to: \n",
    "\n",
    "1. Decide on an appropriate statistical model\n",
    "2. Estimate the model's parameter\n",
    "3. Validate the model against our observations to ensure that it is appropriate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1: Decide on a model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Weibull distribution is one of [many different assumed wind speed distributions](https://www.frontiersin.org/articles/10.3389/fenrg.2021.769920/full) used in wind energy assessment. \n",
    "\n",
    "The Weibull distribution is a two parametric function expressed mathematically as (Perez et al, [2007](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2006JD008278)):\n",
    "\n",
    "![](https://agupubs.onlinelibrary.wiley.com/cms/asset/5632b77b-0544-4101-ad3b-e5dd9610865c/jgrd13704-math-0001.gif)\n",
    "\n",
    "where $v$ is the wind speed, $c$ is the scale factor, and $k$ is the dimensionless shape parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are examples of the Weibull probability function for different parameter choices:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Weibull_PDF.svg/488px-Weibull_PDF.svg.png)\n",
    "\n",
    "_Source: [Wikipedia - Weibull Distribution](https://en.wikipedia.org/wiki/Weibull_distribution)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Functions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In python, we can define [functions](https://www.w3schools.com/python/python_functions.asp) like the ones below that takes two variables as arguments and will return their sum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aPowerB(a,b):\n",
    "    result = a**b\n",
    "    return result\n",
    "\n",
    "def exponentialExample(a,b):\n",
    "    result = np.exp(a+b)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the function is defined, we can use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=2\n",
    "x2=3\n",
    "print('a^b =', aPowerB(x1,x2))\n",
    "print('e^(a=b)= ', exponentialExample(x1,x2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1.1: Code up the Weibull function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions help us modularize our code. We can reuse them over and over without having to retype the operations. \n",
    "\n",
    "Let's now code up the Weibull PDF as a python function. You can use the code stub below.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibullPDF(x,k,c):\n",
    "\n",
    "    f =  # Enter your code on this line # \n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Weibull function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to reproduce the figure above using our newly coded function.\n",
    "\n",
    "If you did it correctly, the figures should look similar. If not check your code... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() \n",
    "\n",
    "klist = [0.5, 1, 1.5, 5]\n",
    "x = np.linspace(0,2.5,100) # This creates 100 x values between 0 and 2.5\n",
    "for k in klist: \n",
    "    pdf = weibullPDF(x,k,1)\n",
    "    plt.plot(x,pdf, label = k)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2: Model Parameter Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to find the parameters that provide the best fit of the Weibull distribution to our wind data.\n",
    "\n",
    "One way of doing so, is to use an optimization algorithm that compares the observed distribution to the theoretical distrubtion. \n",
    "\n",
    "Such algorithms seek to minimize a `penalty function`. \n",
    "\n",
    "**The smaller the penalty value, the better the fit!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Decide on success criterion\n",
    "\n",
    "A commonly used penality function is the Sum of Squares.  \n",
    "\n",
    "$SoS = \\Sigma_i[(y_i - y_{est,i})^2]$\n",
    "\n",
    "Let's code it up below: \n",
    "\n",
    "_Hint: You can use `np.sum()`._ \n",
    "\n",
    "_Running the cell will show you, whether you did it right_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penaltyFunction(y,y_est):\n",
    "    penalty =   # Code up the sum of squares here\n",
    "    return penalty\n",
    "\n",
    "\n",
    "# don't change the lines below\n",
    "y1 = np.array([1,1,3])\n",
    "y2 = np.array([1,1,1])\n",
    "SoS = penaltyFunction(y1,y2)\n",
    "print('Correct SoS = ', 4, 'Your SoS: ', SoS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2.2 Getting observed wind speed probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `np.histogram()` function (which is actually the function used by the pandas histogram, to calculate the observed wind speed probabilities. \n",
    "\n",
    "To do so, use the same numer of bins in the original plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The below code if done correct, will save the probabilities to the probability variable, and also return the edges for each bin\n",
    "observedPDF, binEdges= np.histogram()\n",
    "\n",
    "# The wind speeds are the center of each bin, calculated as (don't change this)\n",
    "windSpeedClass=(binEdges[:-1]+binEdges[1:])/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.2.3: Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put everything together to estimate our parameters. \n",
    "\n",
    "The code below uses two loops to loop over different values for `k` and `c`. \n",
    "\n",
    "Then the code should do the following:\n",
    "\n",
    "1. Calculate the Weibull PDF for the value of `k` and `c` at the wind speed classes from the histogram.\n",
    "2. Calculate the penalty function between the Weibull PDF and the Observed PDF.\n",
    "3. Compare the Penalty Function to the current minimum value of the Penalty function\n",
    "4. If the current Penalty Function is smaller than the current minimum. Update the optimal parameters for\n",
    "   - k\n",
    "   - c\n",
    "   - minimum Penalty function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "n=100\n",
    "ks = np.linspace(0,10,n) # defines the values of k to test\n",
    "print(ks)\n",
    "cs = np.linspace(0,10,n) # defines the values of c to test\n",
    "\n",
    "# Setting intial values, leave unchanged\n",
    "kOpt = []\n",
    "cOpt = []\n",
    "PenaltyOpt = np.inf\n",
    "\n",
    "t1= time.perf_counter()\n",
    "# This code loops over all the k and c values defined above:\n",
    "for k in ks:\n",
    "    for c in cs:\n",
    "        ## Complete the code below to evaluate the weibullPDF for the k and c value (1 line)\n",
    "        modeledPDF = # \n",
    "        ## \n",
    "\n",
    "        ## omplete the code below to calculate the sum of squares beteen the modeledPDF and observedPDF (1 line)\n",
    "        Penalty = \n",
    "        ## \n",
    "\n",
    "        # Compare the Penalty to Optimal Penalty found so far\n",
    "        # If the current penalty is smaller than the optimal Penalty, update kOpt, lOpt, PenaltyOpt to new values\n",
    "        # Update the 4 lines below\n",
    "        if ():\n",
    "            kOpt = #\n",
    "            cOpt = #\n",
    "            PenaltyOpt = #\n",
    "        # \n",
    "\n",
    "t2 = time.perf_counter()\n",
    "duration = t2-t1\n",
    "\n",
    "print(f'The code took {duration:.2f} seconds to run')\n",
    "print('fitted k: ', kOpt, 'fitted l: ', cOpt, 'RMSE: ', PenaltyOpt) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluationg the model\n",
    "\n",
    "We can now investigate how well our model does by plotting things together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "ax = wind_speed['AWND'].hist(bins = 30, density = True)\n",
    "plt.plot(windSpeedClass,weibullPDF(windSpeedClass,kOpt,cOpt))\n",
    "plt.text(15,0.2,f'SOS ={PenaltyOpt:.3f}',fontsize = 12)\n",
    "plt.text(15,0.18,f'k = {kOpt:.3f}',fontsize = 12)\n",
    "plt.text(15,0.16,f'l = {cOpt:.3f}',fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Evaluate Model Performance\n",
    "\n",
    "Change the value of the `n` parameter in the parameter fitting alogrithm. \n",
    "\n",
    "See what happens to the optimal parameters and the time it takes to run. \n",
    "\n",
    "\n",
    "**P.S.: Looping over all values is very inefficient. Numerical solvers, like `scipy.optimize()` will use different techniques. A common optimization algorithm used is [Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent), which avoids having to test all values.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Task 5: Turn the optimization into a function\n",
    "\n",
    "You could turn the entire optimization loops above into a function and then use this function to investigate how the runtime and the optimized parameters change for different values of `n`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a bit of code, that could help you when running your \n",
    "ns = np.logspace(1,5,10)\n",
    "print(ns)\n",
    "\n",
    "runtimes = []\n",
    "cOpts = []\n",
    "kOpts = []\n",
    "\n",
    "for n in ns:\n",
    "    \n",
    "    cOpts.append(n)\n",
    "    kOpts.append(n)\n",
    "    runtimes.append(n)\n",
    "\n",
    "print(runtimes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
